{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d2e965",
   "metadata": {},
   "source": [
    "# Create Data with Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f34810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_label(image_name):\n",
    "    if image_name == '01. No WBS_Homogenous_Infinite Model':  \n",
    "        return np.array([1,0,0,0,0,0,0,0])\n",
    "    elif image_name == '02. WBS_Homogenous_Infinite Model':  \n",
    "        return np.array([0,1,0,0,0,0,0,0])\n",
    "    elif image_name == '03. No WBS_Homogenous_One Fault Model':  \n",
    "        return np.array([0,0,1,0,0,0,0,0])\n",
    "    elif image_name == '04. WBS_Homogenous_One Fault Model':  \n",
    "        return np.array([0,0,0,1,0,0,0,0])\n",
    "    elif image_name == '05. No WBS_Two Porosity PSS_Infinite Model':  \n",
    "        return np.array([0,0,0,0,1,0,0,0])\n",
    "    elif image_name == '06. WBS_Two Porosity PSS_Infinite Model':  \n",
    "        return np.array([0,0,0,0,0,1,0,0])\n",
    "    elif image_name == '07. No WBS_Two Porosity PSS_One Fault Model':  \n",
    "        return np.array([0,0,0,0,0,0,1,0])\n",
    "    elif image_name == '08. WBS_Two Porosity PSS_One Fault Model':  \n",
    "        return np.array([0,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1136d",
   "metadata": {},
   "source": [
    "# Database Before Applying Pre-processing Data Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def raw_data():\n",
    "    dataraw = []\n",
    "    dataraw_dir = \"D:/My Documents/Bismillah Tugas Akhir/Database\"\n",
    "    if not os.path.exists(dataraw_dir):\n",
    "        raise ValueError(\"The directory {} does not exist.\".format(dataraw_dir))\n",
    "    for folder in tqdm(os.listdir(dataraw_dir)):\n",
    "        for img in os.listdir(os.path.join(dataraw_dir,folder)):\n",
    "            path = os.path.join(dataraw_dir,folder, img)\n",
    "            try:\n",
    "                img_data = cv2.imread(path)\n",
    "                dataraw.append([np.array(img_data), create_label(folder)])\n",
    "            except cv2.error as e:\n",
    "                print(\"Error opening image: {}\".format(path))\n",
    "                continue\n",
    "    shuffle(dataraw)\n",
    "    return dataraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataraw = raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menghitung banyaknya data tiap kelas\n",
    "class_count = [0]*8\n",
    "for data in dataraw:\n",
    "    label = np.argmax(data[1])\n",
    "    class_count[label] += 1\n",
    "\n",
    "# Menampilkan histogram\n",
    "labels = ['No WBS_Homogenous_Infinite Model', 'WBS_Homogenous_Infinite Model', 'No WBS_Homogenous_One Fault Model', 'WBS_Homogenous_One Fault Model', 'No WBS_Two Porosity PSS_Infinite Model', 'WBS_Two Porosity PSS_Infinite Model', 'No WBS_Two Porosity PSS_One Fault Model', 'WBS_Two Porosity PSS_One Fault Model']\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "plt.bar(x_pos, class_count, color='green')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Data\")\n",
    "plt.title(\"The Number of Data for Each Class before Pre-processing Data\")\n",
    "plt.xticks(x_pos, labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366291f9",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the original images\n",
    "input_dir = \"D:/My Documents/Bismillah Tugas Akhir/Database/08. WBS_Two Porosity PSS_One Fault Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a61bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the augmented images\n",
    "output_dir = \"D:/My Documents/Bismillah Tugas Akhir/Hasil Augmented Picture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of augmentation techniques to apply\n",
    "augmentations = [\n",
    "    \"shift_left\",\n",
    "    \"shift_right\",\n",
    "    \"shift_up\",\n",
    "    \"shift_down\"\n",
    "]\n",
    "\n",
    "# Loop through each image in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(input_dir, filename))\n",
    "\n",
    "    # Apply each augmentation technique\n",
    "    for i, augmentation in enumerate(augmentations):\n",
    "        # Shift the image to the left\n",
    "        if augmentation == \"shift_left\":\n",
    "            M = np.float32([[1, 0, -150], [0, 1, 0]])\n",
    "            augmented_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "            output_filename = f\"{os.path.splitext(filename)[0]}_shift_left{i}.jpg\"\n",
    "\n",
    "        # Shift the image to the right\n",
    "        elif augmentation == \"shift_right\":\n",
    "            M = np.float32([[1, 0, 200], [0, 1, 0]])\n",
    "            augmented_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "            output_filename = f\"{os.path.splitext(filename)[0]}_shift_right{i}.jpg\"\n",
    "\n",
    "        # Shift the image up\n",
    "        elif augmentation == \"shift_up\":\n",
    "            M = np.float32([[1, 0, 0], [0, 1, -300]])\n",
    "            augmented_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "            output_filename = f\"{os.path.splitext(filename)[0]}_shift_up{i}.jpg\"\n",
    "\n",
    "        # Shift the image down\n",
    "        elif augmentation == \"shift_down\":\n",
    "            M = np.float32([[1, 0, 0], [0, 1, 30]])\n",
    "            augmented_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "            output_filename = f\"{os.path.splitext(filename)[0]}_shift_down{i}.jpg\"\n",
    "\n",
    "        # Save the augmented image to the output directory\n",
    "        cv2.imwrite(os.path.join(output_dir, output_filename), augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006b1b6",
   "metadata": {},
   "source": [
    "# Database After Applying Pre-processing Data Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_data():\n",
    "    database = []\n",
    "    database_dir = \"D:/My Documents/Bismillah Tugas Akhir/Augmented_Database\"\n",
    "    if not os.path.exists(database_dir):\n",
    "        raise ValueError(\"The directory {} does not exist.\".format(database_dir))\n",
    "    for folder in tqdm(os.listdir(database_dir)):\n",
    "        for img in os.listdir(os.path.join(database_dir,folder)):\n",
    "            path = os.path.join(database_dir,folder, img)\n",
    "            try:\n",
    "                img_data = cv2.imread(path)\n",
    "                img_data = img_data.astype('float32')\n",
    "                img_data -= np.mean(img_data) #Zero Centering\n",
    "                img_data = cv2.resize(img_data, (512,512))\n",
    "                database.append([np.array(img_data), create_label(folder)])\n",
    "            except cv2.error as e:\n",
    "                print(\"Error opening image: {}\".format(path))\n",
    "                continue\n",
    "    shuffle(database)\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c88c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menghitung banyaknya data tiap kelas\n",
    "class_count = [0]*8\n",
    "for data in database:\n",
    "    label = np.argmax(data[1])\n",
    "    class_count[label] += 1\n",
    "\n",
    "# Menampilkan histogram\n",
    "labels = ['No WBS_Homogenous_Infinite Model', 'WBS_Homogenous_Infinite Model', 'No WBS_Homogenous_One Fault Model', 'WBS_Homogenous_One Fault Model', 'No WBS_Two Porosity PSS_Infinite Model', 'WBS_Two Porosity PSS_Infinite Model', 'No WBS_Two Porosity PSS_One Fault Model', 'WBS_Two Porosity PSS_One Fault Model']\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "plt.bar(x_pos, class_count, color='green')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Data\")\n",
    "plt.title(\"The Number of Data for Each Class after Pre-processing Data\")\n",
    "plt.xticks(x_pos, labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106deb8",
   "metadata": {},
   "source": [
    "# Splitting Data into Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = database[:700]\n",
    "test = database[700:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,512,512,3)\n",
    "y_train = np.array([i[1] for i in train]).reshape(-1, 8)\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,512,512,3)\n",
    "y_test = np.array([i[1] for i in test]).reshape(-1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf414f2",
   "metadata": {},
   "source": [
    "# Building The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='elu', input_shape=(512, 512, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4d008",
   "metadata": {},
   "source": [
    "# Plot Training & Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train (Accuracy)', 'Test(Val_Accuracy)'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train(Loss)', 'Test(Val_Loss)'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b576a",
   "metadata": {},
   "source": [
    "# Save and Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78098deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('Best_CNN_Zero Centering.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the saved model\n",
    "loaded_model = load_model('Best_CNN_Zero Centering.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84706267",
   "metadata": {},
   "source": [
    "# CNN Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11944e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472396e",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1-score for each class\n",
    "f1_scores = f1_score(y_true_classes, y_pred_classes, average=None)\n",
    "\n",
    "# Plot histogram of F1-scores\n",
    "plt.bar(range(8), f1_scores)\n",
    "plt.xticks(range(8), ['No WBS_Homogenous_Infinite Model', 'WBS_Homogenous_Infinite Model', 'No WBS_Homogenous_One Fault Model', 'WBS_Homogenous_One Fault Model', 'No WBS_Two Porosity PSS_Infinite Model', 'WBS_Two Porosity PSS_Infinite Model', 'No WBS_Two Porosity PSS_One Fault Model', 'WBS_Two Porosity PSS_One Fault Model'], rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score for each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a69eb7",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723983e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_test_data():\n",
    "    data_predict = []\n",
    "    predict_dir = \"D:/My Documents/Bismillah Tugas Akhir/Predict\"\n",
    "    if not os.path.exists(predict_dir):\n",
    "        raise ValueError(\"The directory {} does not exist.\".format(predict_dir))\n",
    "    for img in tqdm(os.listdir(predict_dir)):\n",
    "        path = os.path.join(predict_dir, img)\n",
    "        img_num = img.split('.')[0] \n",
    "        img_data = cv2.imread(path)\n",
    "        try:\n",
    "            img_data = cv2.resize(img_data, (512,512))\n",
    "        except cv2.error as e:\n",
    "            continue\n",
    "        data_predict.append([np.array(img_data), img_num])\n",
    "\n",
    "    shuffle(data_predict)\n",
    "    return data_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48420c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcc8fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_dict = {0: '01. No WBS_Homogenous_Infinite Model',\n",
    "               1: '02. WBS_Homogenous_Infinite Model',\n",
    "               2: '03. No WBS_Homogenous_One Fault Model',\n",
    "               3: '04. WBS_Homogenous_One Fault Model', \n",
    "               4: '05. No WBS_Two Porosity PSS_Infinite Model',\n",
    "               5: '06. WBS_Two Porosity PSS_Infinite Model',\n",
    "               6: '07. No WBS_Two Porosity PSS_One Fault Model', \n",
    "               7: '08. WBS_Two Porosity PSS_One Fault Model'}\n",
    "\n",
    "a, b, c, d, e, f, g, h = 0,0,0,0,0,0,0,0\n",
    "for i in range(len(test_data)):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), dpi=200)\n",
    "    img_data = test_data[i][0]\n",
    "    orig = img_data.reshape(512, 512, 3)\n",
    "    data = img_data.reshape(1, 512, 512, 3)\n",
    "    model_out = loaded_model.predict(data)\n",
    "    label_index = np.argmax(model_out)\n",
    "    str_label = \"Prediction: \" + labels_dict[label_index]\n",
    "    ax.imshow(orig, interpolation='nearest')\n",
    "    ax.set_title(str_label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    file_name = labels_dict[label_index]\n",
    "    \n",
    "    if file_name == labels_dict[0] :\n",
    "        a+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(a)}.jpg\")\n",
    "    elif file_name == labels_dict[1] :\n",
    "        b+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(b)}.jpg\")\n",
    "    elif file_name == labels_dict[2] :\n",
    "        c+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(c)}.jpg\")\n",
    "    elif file_name == labels_dict[3] :\n",
    "        d+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(d)}.jpg\")\n",
    "    elif file_name == labels_dict[4] :\n",
    "        e+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(e)}.jpg\")\n",
    "    elif file_name == labels_dict[5] :\n",
    "        f+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(f)}.jpg\")\n",
    "    elif file_name == labels_dict[6] :\n",
    "        g+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(g)}.jpg\")\n",
    "    elif file_name == labels_dict[7] :\n",
    "        h+=1\n",
    "        fig.savefig(f\"D:/My Documents/Bismillah Tugas Akhir/Predict/Result/{file_name + str(h)}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a0407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KERAS-NEW",
   "language": "python",
   "name": "keras-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
